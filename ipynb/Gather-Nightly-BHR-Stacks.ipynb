{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from plotly.graph_objs import *\n",
    "from moztelemetry import get_pings_properties, get_one_ping_per_client\n",
    "from moztelemetry.dataset import Dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20170228'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startDate = (datetime.today() - timedelta(days=3)).strftime(\"%Y%m%d\")\n",
    "startDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20170303'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endDate = datetime.today().strftime(\"%Y%m%d\")\n",
    "endDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 1.0\n",
    "\n",
    "pings = Dataset.from_source(\"telemetry\") \\\n",
    "    .where(docType='main') \\\n",
    "    .where(appBuildId=lambda b: (b.startswith(startDate) or b > startDate) and (b.startswith(endDate) or b < endDate)) \\\n",
    "    .where(appUpdateChannel=\"nightly\") \\\n",
    "    .records(sc, sample=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "properties = [\"clientId\",\n",
    "              \"environment/system/os/name\",\n",
    "              \"payload/info/subsessionLength\",\n",
    "              \"payload/childPayloads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ping_props = get_pings_properties(pings, properties, with_processes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windows_only(p):\n",
    "    return p[\"environment/system/os/name\"] == \"Windows_NT\"\n",
    "\n",
    "windows_pings_only = ping_props.filter(windows_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17134329"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum = sc.accumulator(0)\n",
    "def calculate_total_sessions_length(ping):\n",
    "    accum.add(ping['payload/info/subsessionLength'])\n",
    "\n",
    "windows_pings_only.foreach(calculate_total_sessions_length)\n",
    "total_sessions_length_s = accum.value\n",
    "total_sessions_length_m = total_sessions_length_s / 60\n",
    "\n",
    "total_sessions_length_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def only_content_hangs(ping):\n",
    "    result = []\n",
    "    if ping['payload/childPayloads'] is None:\n",
    "        return result\n",
    "  \n",
    "    for payload in ping['payload/childPayloads']:\n",
    "        if 'threadHangStats' not in payload:\n",
    "            return result\n",
    "        for thread_hang in payload['threadHangStats']:\n",
    "            if 'name' not in thread_hang:\n",
    "                continue\n",
    "            if thread_hang['name'] != 'Gecko_Child':\n",
    "                continue\n",
    "            if len(thread_hang['hangs']) > 0:\n",
    "                result = result + thread_hang['hangs']\n",
    "    return result\n",
    "       \n",
    "def only_parent_hangs(ping):\n",
    "    result = []\n",
    "  \n",
    "    for thread_hang in ping['payload/threadHangStats']:\n",
    "        if 'name' not in thread_hang:\n",
    "            continue\n",
    "        if thread_hang['name'] != 'Gecko':\n",
    "            continue\n",
    "        if len(thread_hang['hangs']) > 0:\n",
    "            result = result + thread_hang['hangs']\n",
    "    return result\n",
    "    \n",
    "content_hangs = windows_pings_only.flatMap(only_content_hangs)\n",
    "parent_hangs = windows_pings_only.flatMap(only_parent_hangs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scoring is total number of hangs > 100ms, divided by total\n",
    "# sessionLength\n",
    "def map_to_hang_sums(hang):\n",
    "    hist_data = hang['histogram']['values']\n",
    "    hist = pd.Series(hist_data.values(), index=map(int, hist_data.keys()))\n",
    "    hang_sum = hist[hist.index >= 100].sum()\n",
    "    return (tuple(hang['stack']), hang_sum)\n",
    "\n",
    "grouped_content_hangs = content_hangs.map(map_to_hang_sums).reduceByKey(lambda a, b: a + b).collectAsMap()\n",
    "grouped_parent_hangs = content_hangs.map(map_to_hang_sums).reduceByKey(lambda a, b: a + b).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def group_by_top_frame(stacks):\n",
    "    grand_total_hang_sum = 0\n",
    "    top_frames = {}\n",
    "    for stack, hang_sum in stacks.iteritems():\n",
    "        if len(stack) == 0:\n",
    "            continue\n",
    "        stack_top_frame = stack[-1]\n",
    "        if not stack_top_frame in top_frames:\n",
    "            top_frames[stack_top_frame] = { \"frame\": stack_top_frame, \"stacks\": [], \"hang_sum\": 0 }\n",
    "\n",
    "        top_frame = top_frames[stack_top_frame]\n",
    "\n",
    "        # Keep stacks sorted by hits.\n",
    "        top_frame[\"stacks\"].append((stack, hang_sum))\n",
    "        top_frame[\"stacks\"].sort(key=lambda d: d[1], reverse=True)\n",
    "\n",
    "        top_frame[\"hang_sum\"] += hang_sum\n",
    "        grand_total_hang_sum += hang_sum\n",
    "\n",
    "    return top_frames, grand_total_hang_sum\n",
    "\n",
    "content_top_frames, content_grand_total_hang_sum = group_by_top_frame(grouped_content_hangs)\n",
    "parent_top_frames, parent_grand_total_hang_sum = group_by_top_frame(grouped_parent_hangs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(grouping):\n",
    "    grouping['hang_sum'] = float(grouping['hang_sum']) / float(total_sessions_length_m) * 1000\n",
    "    scored_stacks = []\n",
    "    for stack_tuple in grouping['stacks']:\n",
    "        score = float(stack_tuple[1]) / float(total_sessions_length_m) * 1000\n",
    "        scored_stacks.append((stack_tuple[0], score))\n",
    "        \n",
    "    grouping['stacks'] = scored_stacks\n",
    "    return grouping\n",
    "\n",
    "\n",
    "scored_content_top_frames = {k: score(g) for k, g in content_top_frames.iteritems()}\n",
    "scored_parent_top_frames = {k: score(g) for k, g in parent_top_frames.iteritems()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "\n",
    "def write_file(name, stuff):\n",
    "    filename = \"./output/%s-%s-%s.json\" % (name, startDate, endDate)\n",
    "    jsonblob = json.dumps(stuff, ensure_ascii=False)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(jsonblob)\n",
    "\n",
    "write_file('content', scored_content_top_frames)\n",
    "write_file('parent', scored_parent_top_frames)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
